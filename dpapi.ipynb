{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Portability API \n",
        "## Quick Start Demo\n",
        "\n",
        "https://developers.google.com/data-portability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bVudTCLrvdK"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Set up the Data Portability API : https://developers.google.com/data-portability/user-guide/setup\n",
        "\n",
        "\n",
        "Create Credentials file:\n",
        "\n",
        "- Go to https://console.cloud.google.com/apis/credentials.\n",
        "- Click on \"Create Credentials\" and select \"OAuth client ID\".\n",
        "- Select \"Desktop app\" as the application type, give it a name. Click \"Create\".\n",
        "- Click on the download JSON button and save the file as DP_client_secret.json in the root directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMgJfCTHreB3"
      },
      "outputs": [],
      "source": [
        "pip install google-api-python-client google-auth google-auth-httplib2 google-auth-oauthlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QhZmYcW3rodk"
      },
      "outputs": [],
      "source": [
        "from collections.abc import Sequence\n",
        "import io\n",
        "import os\n",
        "import time\n",
        "from typing import Generator\n",
        "import urllib\n",
        "import zipfile\n",
        "\n",
        "from google.oauth2 import credentials\n",
        "import google_auth_oauthlib.flow\n",
        "from googleapiclient import discovery\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qIyOte55sa5_"
      },
      "outputs": [],
      "source": [
        "# The name of a file that contains the OAuth 2.0 information for this\n",
        "# application, including the client_id and client_secret. For this script, this\n",
        "# should be a desktop application OAuth client.\n",
        "CLIENT_SECRETS_FILE = 'DP_client_secret.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6g1nKxGLs5IP"
      },
      "outputs": [],
      "source": [
        "# A list of Data Portability resources that we want to request.\n",
        "RESOURCES = [\n",
        "            # \"maps.ev_profile\",\n",
        "            # \"maps.commute_routes\",\n",
        "            # \"maps.commute_settings\",\n",
        "            # \"maps.photos_videos\",\n",
        "            # \"maps.reviews\",\n",
        "            # \"maps.starred_places\",\n",
        "            # \"myactivity.maps\",\n",
        "            # \"myactivity.shopping\",\n",
        "            # \"myactivity.youtube\",\n",
        "            \"myactivity.search\",\n",
        "            # \"shopping.addresses\",\n",
        "            # \"shopping.reviews\",\n",
        "            # \"youtube.channel\",\n",
        "            # \"youtube.comments\",\n",
        "            # \"youtube.live_chat\",\n",
        "            # \"youtube.music\",\n",
        "            # \"youtube.private_playlists\",\n",
        "            # \"youtube.private_videos\",\n",
        "            # \"youtube.public_playlists\",\n",
        "            # \"youtube.public_videos\",\n",
        "            # \"youtube.shopping\",\n",
        "            # \"youtube.subscriptions\",\n",
        "            # \"youtube.unlisted_playlists\",\n",
        "            # \"youtube.unlisted_videos\"\n",
        "            ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "kcyFFSgltJXc"
      },
      "outputs": [],
      "source": [
        "DATAPORTABILITY_API_SERVICE_NAME = 'dataportability'\n",
        "API_VERSION = 'v1beta'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2lBRhGzItST2"
      },
      "outputs": [],
      "source": [
        "# There is a one to one mapping between Data Portability resources and\n",
        "# dataportability OAuth scopes. The scope code is the resource name plus a\n",
        "# prefix.\n",
        "SCOPE_PREFIX = 'https://www.googleapis.com/auth/dataportability.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# A list of MIME types that are associated with ZIP files.\n",
        "ZIP_MIME_TYPES = ['application/zip', 'application/x-zip', 'application/x-zip-compressed']\n",
        "\n",
        "# Define directory for saving non ZIP files\n",
        "NON_ZIP_FILE_DIRECTORY = 'files'\n",
        "os.makedirs(NON_ZIP_FILE_DIRECTORY, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYsBPypqJ283"
      },
      "source": [
        "## get_credentials function\n",
        "Gets OAuth 2.0 credentials using an installed app OAuth flow.\n",
        "\n",
        "  This generates a link for the user to consent to some or all of the requested\n",
        "  resources. In a production environment, the best practice is to save a refresh\n",
        "  token in Cloud Storage because the access token can expire before the\n",
        "  portability archive job completes.\n",
        "\n",
        "  Args:\n",
        "    resources: A list of dataportability resource IDs. These are OAuth scope\n",
        "    codes from\n",
        "      https://developers.devsite.corp.google.com/data-portability/reference/rest/v1beta/portabilityArchive/initiate#authorization-scopes\n",
        "        without the 'https://www.googleapis.com/auth/dataportability.' prefix.\n",
        "\n",
        "  Returns:\n",
        "    A tuple of credentials containing an access token and a list of resources\n",
        "    for which the user has granted consent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rTT-wS12J1p9"
      },
      "outputs": [],
      "source": [
        "def get_credentials(\n",
        "    resources: Sequence[str],\n",
        ") -> (credentials.Credentials, Sequence[str]):\n",
        "\n",
        "  flow = google_auth_oauthlib.flow.InstalledAppFlow.from_client_secrets_file(\n",
        "      CLIENT_SECRETS_FILE,\n",
        "      [SCOPE_PREFIX + r for r in resources],\n",
        "  )\n",
        "  try:\n",
        "    return flow.run_local_server(port=8082), resources\n",
        "  except Warning as warn:\n",
        "    # We should gracefully handle the user only consenting to a subset of the\n",
        "    # requested scopes.\n",
        "    return credentials.Credentials(warn.token['access_token']), [\n",
        "        scope.removeprefix(SCOPE_PREFIX) for scope in warn.new_scope\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3M2z0IaDK-5g"
      },
      "source": [
        "##  get_api_interface function\n",
        "Gets an interface to the Data Portability API.\n",
        "\n",
        "It takes a credentials.Credentials object as input and returns a discovery.\n",
        "\n",
        "The discovery.Resource object can be used to make calls to the Data Portability API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mTir7HERK_Se"
      },
      "outputs": [],
      "source": [
        "def get_api_interface(\n",
        "    creds: credentials.Credentials,\n",
        ") -> discovery.Resource:\n",
        "\n",
        "    return discovery.build(\n",
        "            serviceName=DATAPORTABILITY_API_SERVICE_NAME,\n",
        "            version=API_VERSION,\n",
        "            credentials=creds,\n",
        "            static_discovery=False,\n",
        "            cache_discovery=False,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCpUBnzWL5vb"
      },
      "source": [
        "## The initiate_portability_archive function\n",
        "It initiates a portability archive for the requested resources. It takes a dataportability.Resource object and a Sequence of strings as input and returns a string. The string is the archive job ID.\n",
        "\n",
        "The function first creates a dataportability.portabilityArchive().initiate() object. The body of the initiate() object is a dictionary that contains a list of resources. The resources are the strings that were passed to the function.\n",
        "\n",
        "The function then calls the execute() method on the initiate() object. The execute() method returns a dictionary that contains the archive job ID. The archive job ID is a unique identifier for the archive job.\n",
        "\n",
        "The function then returns the archive job ID."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "w3ZUdHelL6Ke"
      },
      "outputs": [],
      "source": [
        "def initiate_portability_archive(\n",
        "    dataPortability: discovery.Resource, resources: Sequence[str]\n",
        ") -> str:\n",
        "  initiate = dataPortability.portabilityArchive().initiate(\n",
        "      body={'resources': resources}\n",
        "  )\n",
        "  print(f'👉 Initiating archive...')\n",
        "  print(f\"🔎 method: {initiate.method} \\n🔎 body: {initiate.body}\\n🔎 uri: {initiate.uri}\")\n",
        "  initiate_response = initiate.execute()\n",
        "  print(f\"🔎 Initiate response: {initiate_response}\")\n",
        "  return initiate_response['archiveJobId']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The retry_portability_archive function \n",
        "The function used to retry a failed portability archive job. It takes a dataPortability object and a job_id as input parameters. \n",
        "\n",
        "The function first creates a retry object by calling the archiveJobs().retry method on the dataPortability object.\n",
        "\n",
        "The retry object is then used to call the execute method, which returns a retry_response object. The retry_response object contains the archiveJobId of the newly created job.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retry_portability_archive(\n",
        "    dataPortability: discovery.Resource, job_id\n",
        ") -> str:\n",
        "  retry = dataPortability.archiveJobs().retry(name='archiveJobs/{}'.format(job_id))\n",
        "  print(f\"method: {retry.method} \\nbody: {retry.body}\\nuri: {retry.uri}\")\n",
        "  retry_response = retry.execute()\n",
        "  return retry_response['archiveJobId']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6wwfGL-OIn_"
      },
      "source": [
        "## The poll_get_portability_archive_state function\n",
        "### And exponential_backoff function\n",
        "The exponential_backoff function is a generator function that yields None values at a gradually increasing rate.\n",
        "\n",
        "\n",
        "The poll_get_portability_archive_state function will uses the exponential_backoff function to poll the dataportability API's getPortabilityArchiveState endpoint until the state of the archive job is no longer IN_PROGRESS. The function then returns the URLs of the archive files.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8KyPkBbMOIS6"
      },
      "outputs": [],
      "source": [
        "def exponential_backoff(\n",
        "    delay: float, max_delay: float, multiplier: float\n",
        ") -> Generator[None, None, None]:\n",
        "    while True:\n",
        "        time.sleep(delay)\n",
        "        yield\n",
        "        delay = min(delay * multiplier, max_delay)\n",
        "\n",
        "\n",
        "def poll_get_portability_archive_state(\n",
        "    dataPortability: discovery.Resource, job_id: str\n",
        ") -> Sequence[str]:\n",
        "    while True:\n",
        "        get_state = dataPortability.archiveJobs().getPortabilityArchiveState(\n",
        "            name='archiveJobs/{}/portabilityArchiveState'.format(job_id)\n",
        "        )\n",
        "        print(f'👉 Polling archive status while server indicates state is in progress...')\n",
        "        print(f'🔎 method: {get_state.method}\\n🔎 URI:{get_state.uri} ')\n",
        "        print(\"⏱️ IN_PROGRESS: \", end=\"\", flush=True)\n",
        "        for _ in exponential_backoff(3, 3600, 1.5):\n",
        "            try:\n",
        "                state = get_state.execute()\n",
        "            except Exception as e:\n",
        "                print(f\"❗️ Error: {e}\")\n",
        "                sys.exit()\n",
        "            if state['state'] == 'IN_PROGRESS':\n",
        "                print(\"⬜️\", end=\"\", flush=True)\n",
        "            elif state['state'] == 'FAILED':\n",
        "                print(\"❗️ Job failed. Retrying...\")\n",
        "                # Retry and get new job id\n",
        "                job_id = retry_portability_archive(dataPortability, job_id)\n",
        "                break  # Break out of the exponential backoff loop to retry with new job ID\n",
        "            else:\n",
        "                print(f\"\\n🔎 State: {state}\")\n",
        "                return state['urls']\n",
        "        else:\n",
        "            # If the loop exits normally, without breaking (job completed successfully or failed without retry)\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdb5Ww7V41wV"
      },
      "source": [
        "## The reset_authorization function\n",
        "The function calls the dataportability's reset endpoint. This endpoint resets the authorization for the current user. This is useful if the user has revoked access to the Data Portability API or if the access token has expired.\n",
        "\n",
        "The resetAuthorization method does the following:\n",
        "\n",
        "- Revokes all user-granted OAuth scopes\n",
        "- Allows your application to call InitiatePortabilityArchive for a resource group that you used previously\n",
        "- Removes access to previous data archives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "h_jMqUca4fsJ"
      },
      "outputs": [],
      "source": [
        "def reset_authorization(data_portability: discovery.Resource) -> None:\n",
        "  print('👉 Resetting authorization...')\n",
        "  reset = data_portability.authorization().reset()\n",
        "  print(f\"🔎 method: {reset.method} URI:{reset.uri}\")\n",
        "  try:\n",
        "    initiate_response = reset.execute()\n",
        "    print(f\"🔎 Initiate response: {initiate_response}\")\n",
        "  except Exception as e:\n",
        "    print(f\"❗️ Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC87ZzcM5Rp_"
      },
      "source": [
        "## The download_files function\n",
        "The function downloads files from a list of URLs. It saves non-ZIP files and extracts ZIP files into the archive directory. It determines file names using the 'Content-Disposition' header from the response.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KLVfyDup5Qop"
      },
      "outputs": [],
      "source": [
        "def download_files(urls) -> None:\n",
        "    for url in urls:\n",
        "        try:\n",
        "            print(f'👉 Beginning download. {url}')\n",
        "            url_file = urllib.request.urlopen(url)\n",
        "            print('👍 Download complete!')\n",
        "            content_type = url_file.headers.get('Content-Type')\n",
        "            # Check if the Content-Type is one of the ZIP MIME types\n",
        "            if content_type in ZIP_MIME_TYPES:\n",
        "                # Extract the archive.\n",
        "                print(\"👉 Extracting archive...\")\n",
        "                zf = zipfile.ZipFile(io.BytesIO(url_file.read()), 'r')\n",
        "                # Save extracted files in the current directory.\n",
        "                zf.extractall()\n",
        "                for f in zf.filelist:\n",
        "                    print(f\"📥 File {f.filename} extracted successfully\")\n",
        "            else:\n",
        "                content_disposition = url_file.headers.get('Content-Disposition')\n",
        "                print(f\"👇 File is not a ZIP file:\\n{url_file.headers}\")\n",
        "                content_disposition = url_file.headers.get('Content-Disposition')\n",
        "                # extract filename from content-disposition and save the file\n",
        "                if content_disposition and 'filename=' in content_disposition:\n",
        "                    filename = content_disposition.split('filename=')[-1].strip('\\\"')\n",
        "                    filename = filename.encode('ISO-8859-1').decode('utf-8')\n",
        "                    print(f\"👉 Saving file: {filename}\")\n",
        "                    file_path = os.path.join(NON_ZIP_FILE_DIRECTORY, filename)\n",
        "                    with open(file_path, 'wb') as f:\n",
        "                        f.write(url_file.read())\n",
        "                    print(f\"📁 File {filename} saved successfully\")\n",
        "                else:\n",
        "                    print(\"❗️ The file from the url is not a zip file and does not have a valid filename.\")\n",
        "        except zipfile.BadZipFile:\n",
        "            print(f\"❗️ The file from the url is not a valid ZIP file or is corrupted.\")\n",
        "        except Exception as e:\n",
        "            print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66NuotCB8tDq"
      },
      "source": [
        "# Main code start here:\n",
        "------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "qeY907-88ste",
        "outputId": "cd392a80-36e7-4c8f-c05e-6bbb7ac84219"
      },
      "outputs": [],
      "source": [
        "creds, resources = get_credentials(RESOURCES)\n",
        "print(f'🔎 Obtained OAuth credentials for resources: ', ', '.join(resources))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "ZULXVTLIK9T5",
        "outputId": "f395e5d8-24e4-45cf-e626-270e7ab5e699"
      },
      "outputs": [],
      "source": [
        "data_portability = get_api_interface(creds)\n",
        "job_id = initiate_portability_archive(data_portability, resources)\n",
        "print(f'🔎 Obtained OAuth credentials for resources: ', ', '.join(resources))\n",
        "print(f'👍 Successfully initiated data archive job with ID {job_id}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    urls = poll_get_portability_archive_state(data_portability, job_id)\n",
        "    print(\"👍 Data archive is ready.\")\n",
        "    download_files(urls)\n",
        "except Exception as e:\n",
        "    print(f\"❗️ Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reset_authorization(data_portability)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
